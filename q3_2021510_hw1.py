# -*- coding: utf-8 -*-
"""q3_2021510_HW1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19irW1UOq5YGCKtyvERrz3aw-LS35rP1g
"""

!pip install wandb onnx -Uq

from google.colab import drive
import os

drive.mount('/content/drive')

dest_images_dir = '/content/drive/MyDrive/30_images_masks/images'
dest_masks_dir = '/content/drive/MyDrive/30_images_masks/masks'
c1, c2 = 0, 0
for c in os.listdir(dest_images_dir):
  c1+=1
for c in os.listdir(dest_masks_dir):
  c2+=1
print(c1, c2)

from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms

folder_path = "/content/drive/MyDrive/IDD20K_II"
folders = ['mask_archive', 'image_archive']
for folder in folders:
    folder_files = os.listdir(os.path.join(folder_path, folder))
    print(f"The folder '{folder}' has {len(folder_files)} files.")

import os
from torch.utils.data import Dataset
from PIL import Image
from torchvision import transforms
import random

class_labels = {
    'mask_archive': 0,
    'image_archive': 1
}

class CustomDataset(Dataset):
    image_mask_paths = []

    def __init__(self, img_dir, transform=None, sample_percentage=0.3):
        self.img_dir = img_dir
        self.transform = transform
        self.sample_percentage = 0.3
        self.classes = os.listdir(img_dir)
        print("Classes found:", self.classes)
        self.img_paths = []
        self.mask_paths = {}

        for class_name in self.classes:
            class_dir = os.path.join(img_dir, class_name)
            img_names = [img_name for img_name in os.listdir(class_dir) if img_name.startswith('image_')]
            random.shuffle(img_names)
            num_images_to_select = int(len(img_names) * sample_percentage)
            selected_img_names = img_names[:num_images_to_select]
            for img_name in selected_img_names:
                img_path = os.path.join(class_dir, img_name)
                self.img_paths.append(img_path)
                image_number = int(img_name.split('_')[1].split('.')[0])
                mask_name = f'mask_{image_number}.jpg'
                mask_path = os.path.join(img_dir, 'mask_archive', mask_name)
                self.mask_paths[img_name] = mask_path
                self.image_mask_paths.append((img_path, mask_path))

    def __getitem__(self, index):
        img_path = self.img_paths[index]
        label = class_labels['image_archive']
        img = Image.open(img_path)
        if self.transform:
            img = self.transform(img)

        img_name = os.path.basename(img_path)
        mask_path = self.mask_paths[img_name]
        mask = Image.open(mask_path)
        if self.transform:
            mask = self.transform(mask)

        return img, mask, label

    def __len__(self):
        return len(self.img_paths)

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

dataset = CustomDataset('/content/drive/MyDrive/IDD20K_II', transform=transform)

image_mask_paths = CustomDataset.image_mask_paths
print(image_mask_paths)

import shutil

dest_images_dir = '/content/drive/MyDrive/30_images_masks/images'
dest_masks_dir = '/content/drive/MyDrive/30_images_masks/masks'

for img_path, mask_path in image_mask_paths:
  img_name = os.path.basename(img_path)
  mask_name = os.path.basename(mask_path)
  shutil.copy(img_path, os.path.join(dest_images_dir, img_name))
  shutil.copy(mask_path, os.path.join(dest_masks_dir, mask_name))

dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)

import os
import matplotlib.pyplot as plt
from PIL import Image

image_folder = "/content/drive/MyDrive/IDD20K_II/image_archive/"
mask_folder = "/content/drive/MyDrive/IDD20K_II/mask_archive/"

class_colors = {
    0: [0, 0, 0],
    1: [255, 0, 0],
    2: [0, 255, 0],
}
def display_samples(start_idx, end_idx):
    num_rows = end_idx - start_idx + 1
    num_columns = 2
    fig, axes = plt.subplots(num_rows, num_columns, figsize=(10, 10))

    for i in range(start_idx, end_idx + 1):
        sample = f'image_{i}.jpg'
        sample_mask = f'mask_{i}.jpg'
        image_path = os.path.join(image_folder, sample)
        mask_path = os.path.join(mask_folder, sample_mask)

        image = Image.open(image_path)
        mask = Image.open(mask_path)
        ind = i - start_idx
        axes[ind, 0].imshow(image)
        axes[ind, 0].set_title(f'Image {i}')
        axes[ind, 0].axis('off')

        axes[ind, 1].imshow(mask)
        axes[ind, 1].set_title(f'Mask {i}')
        axes[ind, 1].axis('off')

    plt.tight_layout()
    plt.show()

display_samples(start_idx=1014, end_idx=1019)

pip install torch torchvision

model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)
model.eval()

"""don't use this"""

import os
from PIL import Image
import matplotlib.pyplot as plt
output_dir = "/content/drive/MyDrive/output_mask"

files = os.listdir(output_dir)
i=0
for file in files:
    if(i==5):
      break
    i+=1
    if file.endswith(".jpg"):
        file_path = os.path.join(output_dir, file)
        image = Image.open(file_path)
        plt.imshow(image)
        plt.axis("off")
        plt.show()

"""Today final inference

"""

import os
import torch
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
from tqdm import tqdm

relevant_classes = ['Road', 'Sidewalk', 'Person', 'Rider', 'Motorbike', 'Bicycle', 'Car', 'Truck', 'Bus',
                    'Train', 'Wall', 'Fence', 'Traffic Sign', 'Traffic Light', 'Pole', 'Building',
                    'Vegetation', 'Sky']

cityscapes_class_ids = {
    'Road': 0+1, 'Sidewalk': 2, 'Person':4, 'Rider': 5, 'Motorbike':6, 'Bicycle': 7,
    'Car': 9, 'Truck': 10, 'Bus': 11, 'Train': 12, 'Wall': 14, 'Fence': 15,
    'Traffic Sign': 18, 'Traffic Light': 19, 'Pole': 20, 'Building': 22,
    'Vegetation': 24, 'Sky': 25
}

class_colors = {
    1: [128, 64, 128],
    2: [244, 35, 232],
    4: [220, 20, 60],
    5: [0, 0, 230],
    6: [0, 0, 142],
    7: [119, 11, 32],
    9: [0, 0, 230],
    10: [0, 0, 70],
    11: [0, 0, 70],
    12: [0, 0, 70],
    14: [102, 102, 156],
    15: [190, 153, 153],
    18: [220, 220, 0],
    19: [250, 170, 30],
    20: [153, 153, 153],
    22: [70, 70, 70],
    24: [107, 142, 35],
    25: [70, 130, 180],
}

transform = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

def inference_image(image, model, transform, device):
    with torch.no_grad():
        image = transform(image).unsqueeze(0).to(device)
        output = model(image)['out'][0]
        output = torch.argmax(output, dim=0).cpu().numpy()
    return output

def colorize_mask(mask, class_colors):
    colored_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)
    for class_id, color in class_colors.items():
        colored_mask[mask == class_id] = color
    return colored_mask


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)
model.eval()
model.to(device)


images_dir = "/content/drive/MyDrive/30_images_masks/images"
masks_dir = "/content/drive/MyDrive/30_images_masks/masks"
output_dir = "/content/drive/MyDrive/output_mask"


os.makedirs(output_dir, exist_ok=True)


image_paths = sorted(os.listdir(images_dir))
mask_paths = sorted(os.listdir(masks_dir))
for image_name, mask_name in tqdm(zip(image_paths, mask_paths), desc="Performing inference"):
    image_path = os.path.join(images_dir, image_name)
    mask_path = os.path.join(masks_dir, mask_name)

    image = Image.open(image_path).convert("RGB")

    output = inference_image(image, model, transform, device)

    relevant_class_ids = [cityscapes_class_ids[class_name] for class_name in relevant_classes]
    filtered_output = np.where(np.isin(output, relevant_class_ids), output, 0)

    colored_output = colorize_mask(filtered_output, class_colors)

    output_name = mask_name.split('.')[0] + '_colored.jpg'
    output_path = os.path.join(output_dir, output_name)
    colorized_segmentation_mask = Image.fromarray(colored_output)
    colorized_segmentation_mask.save(output_path, "JPEG")

print("Inference completed.")

import os
from PIL import Image
import matplotlib.pyplot as plt

image_dir = "/content/drive/MyDrive/30_images_masks/images/"
output_dir = "/content/drive/MyDrive/output_mask"

output_files = sorted(os.listdir(output_dir))
i=0
for output_file in output_files:
    if(i==5):
      break
    i+=1
    if output_file.endswith(".jpg"):
        image_file = output_file.split('.')[0] + '.jpg'
        image_file = 'image_'+image_file.split('_')[1]
        image_path = os.path.join(image_dir, image_file)
        output_path = os.path.join(output_dir, output_file)

        if os.path.exists(image_path):
            try:
                image = Image.open(image_path)
                plt.subplot(1, 2, 1)
                plt.imshow(image)
                plt.title("Original Image")
                plt.axis("off")

                mask = Image.open(output_path)
                plt.subplot(1, 2, 2)
                plt.imshow(mask)
                plt.title("Segmentation Mask")
                plt.axis("off")

                plt.show()
            except Exception as e:
                print(f"Error displaying images: {e}")
        else:
            print(f"Image file not found: {image_path}")

output_dir = "/content/drive/MyDrive/output_mask"

# Iterate over each file in the directory
for filename in os.listdir(output_dir):
    # Check if the file name ends with "_colored.jpg"
    if filename.endswith("_colored.jpg"):
        # Construct the new file name by removing "_colored"
        new_filename = filename.replace("_colored.jpg", ".jpg")
        # Rename the file
        os.rename(os.path.join(output_dir, filename), os.path.join(output_dir, new_filename))
        print(f"Renamed {filename} to {new_filename}")

print("File renaming completed.")

masks_dir = "/content/drive/MyDrive/30_images_masks/masks"
output_dir = "/content/drive/MyDrive/output_mask"

masks_files = set(os.listdir(masks_dir))
output_files = set(os.listdir(output_dir))

unique_masks_files = masks_files - output_files
unique_output_files = output_files - masks_files

unique_masks_files = list(unique_masks_files)
unique_output_files = list(unique_output_files)

# for file_name in unique_output_files:
#     file_path = os.path.join(output_dir, file_name)
#     os.remove(file_path)

print("Files unique to masks directory:", unique_masks_files)
print("Files unique to output directory:", unique_output_files)



import os
import numpy as np
from PIL import Image
import tensorflow as tf
from tqdm import tqdm
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from google.colab import drive
import os

drive.mount('/content/drive')

masks_dir = "/content/drive/MyDrive/30_images_masks/masks"
ground_truth_masks = [tf.convert_to_tensor(np.array(Image.open(os.path.join(masks_dir, mask_name)))) for mask_name in sorted(os.listdir(masks_dir))]

output_dir = "/content/drive/MyDrive/output_mask"
generated_masks = [tf.convert_to_tensor(np.array(Image.open(os.path.join(output_dir, mask_name)))) for mask_name in sorted(os.listdir(output_dir))]

import os
import torch
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
from tqdm import tqdm
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

relevant_classes = ['Road', 'Sidewalk', 'Person', 'Rider', 'Motorbike', 'Bicycle', 'Car', 'Truck', 'Bus',
                    'Train', 'Wall', 'Fence', 'Traffic Sign', 'Traffic Light', 'Pole', 'Building',
                    'Vegetation', 'Sky']
cityscapes_class_ids = {
    'Road': 0+1, 'Sidewalk': 2, 'Person':4, 'Rider': 5, 'Motorbike':6, 'Bicycle': 7,
    'Car': 9, 'Truck': 10, 'Bus': 11, 'Train': 12, 'Wall': 14, 'Fence': 15,
    'Traffic Sign': 18, 'Traffic Light': 19, 'Pole': 20, 'Building': 22,
    'Vegetation': 24, 'Sky': 25
}

transform = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

def inference_image(image, model, transform, device, gt_mask, metrics):
    with torch.no_grad():
        image = transform(image).unsqueeze(0).to(device)
        output = model(image)['out'][0]
        output = torch.argmax(output, dim=0).cpu().numpy()

        if gt_mask.shape != output.shape:
            raise ValueError("Shapes of ground truth mask and predicted output are not consistent.")

        metrics['pixel_accuracy'].append(accuracy_score(gt_mask.flatten(), output.flatten()))
        metrics['precision'].append(precision_score(gt_mask.flatten(), output.flatten(), average='weighted'))
        metrics['recall'].append(recall_score(gt_mask.flatten(), output.flatten(), average='weighted'))
        metrics['f1_score'].append(f1_score(gt_mask.flatten(), output.flatten(), average='weighted'))
        metrics['conf_matrix'] += confusion_matrix(gt_mask.flatten(), output.flatten(), labels=list(range(len(relevant_classes))))

    return output

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)
model.eval()
model.to(device)

images_dir = "/content/drive/MyDrive/30_images_masks/images"
masks_dir = "/content/drive/MyDrive/30_images_masks/masks"
output_dir = "/content/drive/MyDrive/output_mask"

os.makedirs(output_dir, exist_ok=True)

metrics = {
    'pixel_accuracy': [],
    'precision': [],
    'recall': [],
    'f1_score': [],
    'conf_matrix': np.zeros((len(relevant_classes), len(relevant_classes)), dtype=np.int64)
}

image_paths = sorted(os.listdir(images_dir))
mask_paths = sorted(os.listdir(masks_dir))
for image_name, mask_name in tqdm(zip(image_paths, mask_paths), desc="Performing inference and calculating metrics"):
    image_path = os.path.join(images_dir, image_name)
    mask_path = os.path.join(masks_dir, mask_name)

    image = Image.open(image_path).convert("RGB").resize((512, 512))
    gt_mask = np.array(Image.open(mask_path).convert("L").resize((512, 512)))

    output = inference_image(image, model, transform, device, gt_mask, metrics)
    output_name = mask_name.split('.')[0] + '.jpg'
    output_path = os.path.join(output_dir, output_name)
    segmentation_mask = Image.fromarray(output.astype(np.uint8))
    segmentation_mask.save(output_path, "JPEG")

conf_matrix = metrics['conf_matrix']
IoUs = np.zeros(len(relevant_classes))
for i in range(len(relevant_classes)):
    tp = conf_matrix[i, i]
    fp = np.sum(conf_matrix[:, i]) - tp
    fn = np.sum(conf_matrix[i, :]) - tp
    IoUs[i] = tp / (tp + fp + fn)

mAP = np.mean(IoUs)
IoU_by_class = {class_name: IoU for class_name, IoU in zip(relevant_classes, IoUs)}

print("Pixel-wise accuracy:", np.mean(metrics['pixel_accuracy']))
print("Mean Average Precision (mAP):", mAP)
print("Intersection over Union (IoU) by class:", IoU_by_class)
print("Precision:", np.mean(metrics['precision']))
print("Recall:", np.mean(metrics['recall']))
print("F1 Score:", np.mean(metrics['f1_score']))
print("Confusion Matrix:\n", conf_matrix)

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data = np.array(conf_matrix)
relevant_classes = ['Road', 'Sidewalk', 'Person', 'Rider', 'Motorbike', 'Bicycle', 'Car', 'Truck', 'Bus',
                    'Train', 'Wall', 'Fence', 'Traffic Sign', 'Traffic Light', 'Pole', 'Building',
                    'Vegetation', 'Sky']

confusion_matrix = data.T

plt.figure(figsize=(12, 10))
sns.heatmap(confusion_matrix, annot=True, fmt="d", cmap="YlGnBu", xticklabels=relevant_classes, yticklabels=relevant_classes)
plt.xlabel('Predicted Classes')
plt.ylabel('Ground Truth Classes')
plt.title('Confusion Matrix')
plt.show()

precision = np.zeros(len(relevant_classes))
recall = np.zeros(len(relevant_classes))
f1_score = np.zeros(len(relevant_classes))

for i in range(len(relevant_classes)):
    tp = confusion_matrix[i, i]
    fp = np.sum(confusion_matrix[:, i]) - tp
    fn = np.sum(confusion_matrix[i, :]) - tp

    precision = np.zeros(len(relevant_classes))
    recall = np.zeros(len(relevant_classes))
    f1_score = np.zeros(len(relevant_classes))
    c=0
    for i in range(len(relevant_classes)):
        tp = confusion_matrix[i, i]
        fp = np.sum(confusion_matrix[:, i]) - tp
        fn = np.sum(confusion_matrix[i, :]) - tp
        c+=1
        if (tp + fp) > 0:
            precision[i] = tp / (tp + fp)
        else:
            precision[i] = 0

        if (tp + fn) > 0:
            c-=1
            recall[i] = tp / (tp + fn)
        else:
            recall[i] = 0

        if (precision[i] + recall[i]) > 0:
            c+=1
            f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])
        else:
            f1_score[i] = 0

for i, class_name in enumerate(relevant_classes):
    print("Class: ", class_name)
    print("Precision: ", precision[i])
    print("Recall: ",recall[i])
    print("F1 Score: ",f1_score[i])
    print("-----------------------")

mean_f1_score = np.mean(f1_score)
print(f"Mean F1 Score: {mean_f1_score:.4f}")

threshold = mean_f1_score
classes_well = []
for i in range(len(relevant_classes)):
    if f1_score[i] >= threshold:
        classes_well.append({"Class": relevant_classes[i], "F1 Score": f1_score[i]})
classes_improve = []
for i in range(len(relevant_classes)):
    if f1_score[i] < threshold:
        classes_improve.append({"Class": relevant_classes[i], "F1 Score": f1_score[i]})

print("Classes where the model performs well: ",classes_well)
print("Classes where improvement is needed: ",classes_improve)

class_colors = {
    1: [128, 64, 128],
    2: [244, 35, 232],
    4: [220, 20, 60],
    5: [0, 0, 230],
    6: [0, 0, 142],
    7: [119, 11, 32],
    9: [0, 0, 230],
    10: [0, 0, 70],
    11: [0, 0, 70],
    12: [0, 0, 70],
    14: [102, 102, 156],
    15: [190, 153, 153],
    18: [220, 220, 0],
    19: [250, 170, 30],
    20: [153, 153, 153],
    22: [70, 70, 70],
    24: [107, 142, 35],
    25: [70, 130, 180],
}
def visualize_masks(image, gt_mask, pred_mask, class_name):
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    axes[0].imshow(image)
    axes[0].set_title("Image")
    axes[0].axis('off')

    axes[1].imshow(gt_mask, cmap='gray')
    axes[1].set_title("Ground Truth Mask")
    axes[1].axis('off')
    colored_pred_mask = np.zeros_like(image)
    for class_id, color in class_colors.items():
        colored_pred_mask[pred_mask == class_id] = color
    axes[2].imshow(colored_pred_mask)
    axes[2].set_title("Predicted Mask")
    axes[2].axis('off')

    plt.suptitle(f"Class: {class_name}")
    plt.show()

for class_name in relevant_classes:
    indices = np.where(IoU_by_class[class_name] <= 0.5)[0]
    if len(indices) == 0:
        print(f"No images with IoU <= 0.5 for class: {class_name}")
        continue

    print(f"Visualizing images with IoU <= 0.5 for class: {class_name}")
    count = 0
    for i in indices:
        image_name = image_paths[i]
        mask_name = mask_paths[i]

        image_path = os.path.join(images_dir, image_name)
        mask_path = os.path.join(masks_dir, mask_name)

        image = Image.open(image_path).convert("RGB").resize((512, 512))
        gt_mask = np.array(Image.open(mask_path).convert("L").resize((512, 512)))
        pred_mask = np.array(Image.open(os.path.join(output_dir, mask_name.split('.')[0] + '.jpg')).resize((512, 512)))

        if np.mean(gt_mask == cityscapes_class_ids[class_name]) == 0:
            continue

        visualize_masks(image, gt_mask == cityscapes_class_ids[class_name], pred_mask, class_name)
        count += 1
        if count == 3:
            break

import os
import  matplotlib.pyplot as plt
from PIL import Image
import numpy as np
cityscapes_class_ids = {
    'Road': 0+1, 'Sidewalk': 2, 'Person':4, 'Rider': 5, 'Motorbike':6, 'Bicycle': 7,
    'Car': 9, 'Truck': 10, 'Bus': 11, 'Train': 12, 'Wall': 14, 'Fence': 15,
    'Traffic Sign': 18, 'Traffic Light': 19, 'Pole': 20, 'Building': 22,
    'Vegetation': 24, 'Sky': 25
}
label_folder = "/content/drive/MyDrive/30_images_masks/masks"

class_counts = {}
for class_name in cityscapes_class_ids.keys():
    class_counts[class_name] = 0

for label_file in os.listdir(label_folder):
    label_path = os.path.join(label_folder, label_file)
    label = np.array(Image.open(label_path))

    for class_name, class_value in cityscapes_class_ids.items():
        class_counts[class_name] = class_counts[class_name]+np.sum(label == class_value)

plt.bar(class_counts.keys(), class_counts.values())
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Data Distribution Across Classes')
plt.show()